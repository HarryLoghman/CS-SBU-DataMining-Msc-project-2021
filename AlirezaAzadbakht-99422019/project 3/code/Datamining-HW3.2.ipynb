{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,cross_validate\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# config\n",
    "def make_report(y_pred , y_true):\n",
    "    print (\"\")\n",
    "    print (\"Classification Report: \")\n",
    "    print (classification_report(y_true, y_pred))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "    plt.show()\n",
    "    \n",
    "def reg_report(true, pred, name='Test', is_print = True):\n",
    "    acc = ((pred<=true*1.1) & (true*0.9<=pred)).mean()\n",
    "    rmse = mean_squared_error(true, pred, squared=False)\n",
    "    if is_print:\n",
    "        print(\"\\n{} Results :\\n\".format(name))\n",
    "        print('RMSE :',rmse)\n",
    "        print('Accuracy with 5% :', acc)\n",
    "    return rmse, acc\n",
    "\n",
    "def eval_report(y_train, pred_train,y_test, pred_test,is_print = True):\n",
    "    train_rmse, train_acc = reg_report(y_train, pred_train,is_print=is_print, name='Train',)\n",
    "    test_rmse, test_acc = reg_report(y_test, pred_test,is_print=is_print, name='Test')\n",
    "    return train_rmse, train_acc, test_rmse, test_acc\n",
    "pd.set_option('display.max_columns', 50)\n",
    "path = 'datasets/University/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3455, 9)\n",
      "(485, 9)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(path+'Bitcoin Historical Data - Investing.com.csv', thousands=',')\n",
    "data['Date'] = pd.to_datetime(data.Date)\n",
    "data['target'] = data['Price'].shift(1)\n",
    "data = data.dropna()\n",
    "data['label'] = data['target'] - data['Price']\n",
    "data['label'] = (data['label'] / abs(data['label'])) + 1\n",
    "data['label'] = data['label'] /2\n",
    "data['Vol.'] = pd.to_numeric(data['Vol.'].apply(lambda x: x[:-1]))\n",
    "data['Change %'] = pd.to_numeric(data['Change %'].apply(lambda x: x[:-1]))\n",
    "data = data.fillna(0)\n",
    "train = data[data.Date < '2020-01-02' ]\n",
    "test = data[data.Date >= '2020-01-02' ]\n",
    "feat = ['Price', 'Open', 'High', 'Low', 'Vol.', 'Change %']\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69685719.65019138, tolerance: 4108734.2002128786\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.015530</td>\n",
       "      <td>15494.760691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>93.687592</td>\n",
       "      <td>16436.542301</td>\n",
       "      <td>0.673227</td>\n",
       "      <td>0.674227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>309.761436</td>\n",
       "      <td>15885.348732</td>\n",
       "      <td>0.309407</td>\n",
       "      <td>0.686598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>89.028112</td>\n",
       "      <td>15665.662052</td>\n",
       "      <td>0.984660</td>\n",
       "      <td>0.694845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>128.167008</td>\n",
       "      <td>15692.101834</td>\n",
       "      <td>0.692041</td>\n",
       "      <td>0.698969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>204.181024</td>\n",
       "      <td>1096.602733</td>\n",
       "      <td>0.679595</td>\n",
       "      <td>0.979381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>204.181024</td>\n",
       "      <td>1096.602733</td>\n",
       "      <td>0.679595</td>\n",
       "      <td>0.979381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>204.181789</td>\n",
       "      <td>1096.353084</td>\n",
       "      <td>0.680174</td>\n",
       "      <td>0.979381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BayesianRidge()</td>\n",
       "      <td>204.183926</td>\n",
       "      <td>1096.563582</td>\n",
       "      <td>0.679884</td>\n",
       "      <td>0.979381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>206.657296</td>\n",
       "      <td>1120.954733</td>\n",
       "      <td>0.813314</td>\n",
       "      <td>0.979381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Train RMSE     Test RMSE  Train Accuracy  \\\n",
       "8      DecisionTreeRegressor    0.015530  15494.760691        1.000000   \n",
       "9          CatBoostRegressor   93.687592  16436.542301        0.673227   \n",
       "6          AdaBoostRegressor  309.761436  15885.348732        0.309407   \n",
       "5      RandomForestRegressor   89.028112  15665.662052        0.984660   \n",
       "7  GradientBoostingRegressor  128.167008  15692.101834        0.692041   \n",
       "0           LinearRegression  204.181024   1096.602733        0.679595   \n",
       "1                      Ridge  204.181024   1096.602733        0.679595   \n",
       "2                      Lasso  204.181789   1096.353084        0.680174   \n",
       "3            BayesianRidge()  204.183926   1096.563582        0.679884   \n",
       "4               MLPRegressor  206.657296   1120.954733        0.813314   \n",
       "\n",
       "   Test Accuracy  \n",
       "8       0.651546  \n",
       "9       0.674227  \n",
       "6       0.686598  \n",
       "5       0.694845  \n",
       "7       0.698969  \n",
       "0       0.979381  \n",
       "1       0.979381  \n",
       "2       0.979381  \n",
       "3       0.979381  \n",
       "4       0.979381  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {\n",
    "    'LinearRegression':LinearRegression(),\n",
    "    'Ridge':Ridge(),\n",
    "    'Lasso':Lasso(),\n",
    "    'BayesianRidge()':BayesianRidge(),\n",
    "    'MLPRegressor':MLPRegressor(),\n",
    "    'RandomForestRegressor':RandomForestRegressor(),\n",
    "    'AdaBoostRegressor':AdaBoostRegressor(),\n",
    "    'GradientBoostingRegressor':GradientBoostingRegressor(),\n",
    "    'DecisionTreeRegressor':DecisionTreeRegressor(),\n",
    "    'CatBoostRegressor':CatBoostRegressor(verbose=0)\n",
    "}\n",
    "\n",
    "result = pd.DataFrame(columns = ['Model', \"Train RMSE\", \"Test RMSE\", \"Train Accuracy\", \"Test Accuracy\"])\n",
    "for name, model in models.items():\n",
    "    model.fit(train[feat], train['target'])\n",
    "    train_pred = model.predict(train[feat])\n",
    "    pred = model.predict(test[feat])\n",
    "    train_rmse, train_acc, test_rmse, test_acc = eval_report(y_train = train['target'], \n",
    "                                                             pred_train = train_pred, \n",
    "                                                             y_test = test['target'],\n",
    "                                                             pred_test = pred,\n",
    "                                                            is_print = False)\n",
    "    result = result.append({'Model': name, \"Train RMSE\":train_rmse, \"Test RMSE\":test_rmse, \"Train Accuracy\":train_acc, \"Test Accuracy\":test_acc}, ignore_index = True)\n",
    "\n",
    "display(result.sort_values('Test Accuracy'))\n",
    "result.to_csv(path+'result-10model.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69685719.65019138, tolerance: 4108734.2002128786\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Results :\n",
      "\n",
      "RMSE : 205.96305347824543\n",
      "Accuracy with 5% : 0.685383502170767\n",
      "\n",
      "Test Results :\n",
      "\n",
      "RMSE : 1132.6780972525842\n",
      "Accuracy with 5% : 0.9752577319587629\n"
     ]
    }
   ],
   "source": [
    "model = VotingRegressor([('Lasso', Lasso()),\n",
    "                         ('BayesianRidge', BayesianRidge()),\n",
    "                         ('MLPRegressor', MLPRegressor())])\n",
    "model.fit(train[feat], train['target'])\n",
    "train_pred = model.predict(train[feat])\n",
    "pred = model.predict(test[feat])\n",
    "train_rmse, train_acc, test_rmse, test_acc = eval_report(y_train = train['target'], \n",
    "                                                             pred_train = train_pred, \n",
    "                                                             y_test = test['target'],\n",
    "                                                             pred_test = pred,\n",
    "                                                            is_print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69685719.65019138, tolerance: 4108734.2002128786\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Results :\n",
      "\n",
      "RMSE : 205.0645017748052\n",
      "Accuracy with 5% : 0.6850940665701881\n",
      "\n",
      "Test Results :\n",
      "\n",
      "RMSE : 1086.3938782976395\n",
      "Accuracy with 5% : 0.9835051546391752\n"
     ]
    }
   ],
   "source": [
    "model1 = Lasso()                  \n",
    "model2 = BayesianRidge()                \n",
    "model3 = MLPRegressor()\n",
    "\n",
    "model1.fit(train[feat], train['target'])\n",
    "train_pred1 = model1.predict(train[feat])\n",
    "pred1 = model1.predict(test[feat])\n",
    "\n",
    "model2.fit(train[feat], train['target'])\n",
    "train_pred2 = model2.predict(train[feat])\n",
    "pred2 = model2.predict(test[feat])\n",
    "\n",
    "model3.fit(train[feat], train['target'])\n",
    "train_pred3 = model3.predict(train[feat])\n",
    "pred3 = model3.predict(test[feat])\n",
    "\n",
    "pred = (pred1+pred2+pred3)/3\n",
    "train_pred = (train_pred1+train_pred2+train_pred3)/3\n",
    "train_rmse, train_acc, test_rmse, test_acc = eval_report(y_train = train['target'], \n",
    "                                                             pred_train = train_pred, \n",
    "                                                             y_test = test['target'],\n",
    "                                                             pred_test = pred,\n",
    "                                                            is_print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69685719.65019138, tolerance: 4108734.2002128786\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Results :\n",
      "\n",
      "RMSE : 204.99367317582505\n",
      "Accuracy with 5% : 0.6879884225759768\n",
      "\n",
      "Test Results :\n",
      "\n",
      "RMSE : 1102.0326468190078\n",
      "Accuracy with 5% : 0.9814432989690721\n"
     ]
    }
   ],
   "source": [
    "boost_train_x = train[feat].copy()\n",
    "boost_test_x = test[feat].copy()\n",
    "boost_train_y = train['target'].copy()\n",
    "boost_test_y = test['target'].copy()\n",
    "\n",
    "\n",
    "model1 = Lasso()                  \n",
    "model2 = BayesianRidge()                \n",
    "model3 = MLPRegressor()\n",
    "\n",
    "model1.fit(boost_train_x, boost_train_y)\n",
    "boost_train_x['pred1'] = model1.predict(boost_train_x)\n",
    "boost_test_x['pred1'] = model1.predict(boost_test_x)\n",
    "\n",
    "model2.fit(boost_train_x, boost_train_y)\n",
    "boost_train_x['pred2'] = model2.predict(boost_train_x)\n",
    "boost_test_x['pred2'] = model2.predict(boost_test_x)\n",
    "\n",
    "model3.fit(boost_train_x, boost_train_y)\n",
    "train_pred = model3.predict(boost_train_x)\n",
    "pred = model3.predict(boost_test_x)\n",
    "\n",
    "pred = (pred1+pred2+pred3)/3\n",
    "train_pred = (train_pred1+train_pred2+train_pred3)/3\n",
    "train_rmse, train_acc, test_rmse, test_acc = eval_report(y_train = train['target'], \n",
    "                                                             pred_train = train_pred, \n",
    "                                                             y_test = test['target'],\n",
    "                                                             pred_test = pred,\n",
    "                                                            is_print = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>277.002331</td>\n",
       "      <td>16241.628269</td>\n",
       "      <td>0.318090</td>\n",
       "      <td>0.684536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>291.516007</td>\n",
       "      <td>15845.107007</td>\n",
       "      <td>0.294356</td>\n",
       "      <td>0.684536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>square</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>310.031233</td>\n",
       "      <td>15579.580213</td>\n",
       "      <td>0.427786</td>\n",
       "      <td>0.684536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>square</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>297.300346</td>\n",
       "      <td>15595.778555</td>\n",
       "      <td>0.374240</td>\n",
       "      <td>0.686598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>290.551777</td>\n",
       "      <td>16011.126391</td>\n",
       "      <td>0.389291</td>\n",
       "      <td>0.688660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.9</td>\n",
       "      <td>150</td>\n",
       "      <td>313.094121</td>\n",
       "      <td>15844.606365</td>\n",
       "      <td>0.375109</td>\n",
       "      <td>0.688660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>square</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>291.018006</td>\n",
       "      <td>15791.047779</td>\n",
       "      <td>0.304776</td>\n",
       "      <td>0.688660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>exponential</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>276.288132</td>\n",
       "      <td>16087.273380</td>\n",
       "      <td>0.327062</td>\n",
       "      <td>0.690722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>square</td>\n",
       "      <td>0.2</td>\n",
       "      <td>150</td>\n",
       "      <td>308.350599</td>\n",
       "      <td>15714.439825</td>\n",
       "      <td>0.360926</td>\n",
       "      <td>0.690722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>exponential</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>313.539755</td>\n",
       "      <td>16008.140817</td>\n",
       "      <td>0.382923</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>exponential</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>327.840565</td>\n",
       "      <td>15958.289857</td>\n",
       "      <td>0.308828</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>square</td>\n",
       "      <td>0.9</td>\n",
       "      <td>150</td>\n",
       "      <td>367.815420</td>\n",
       "      <td>15534.447533</td>\n",
       "      <td>0.298698</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>square</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>315.195045</td>\n",
       "      <td>15584.591920</td>\n",
       "      <td>0.336903</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>exponential</td>\n",
       "      <td>0.9</td>\n",
       "      <td>150</td>\n",
       "      <td>538.435011</td>\n",
       "      <td>16000.225061</td>\n",
       "      <td>0.307959</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>square</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>319.080274</td>\n",
       "      <td>15723.891137</td>\n",
       "      <td>0.278726</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>306.810114</td>\n",
       "      <td>15843.304183</td>\n",
       "      <td>0.413893</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>exponential</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150</td>\n",
       "      <td>403.736089</td>\n",
       "      <td>15930.117280</td>\n",
       "      <td>0.309696</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>150</td>\n",
       "      <td>272.211613</td>\n",
       "      <td>16218.307735</td>\n",
       "      <td>0.317221</td>\n",
       "      <td>0.694845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>272.368052</td>\n",
       "      <td>16001.072291</td>\n",
       "      <td>0.319537</td>\n",
       "      <td>0.694845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>exponential</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>304.704885</td>\n",
       "      <td>15937.346085</td>\n",
       "      <td>0.363531</td>\n",
       "      <td>0.696907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>exponential</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>297.221861</td>\n",
       "      <td>15924.448774</td>\n",
       "      <td>0.288567</td>\n",
       "      <td>0.696907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>309.321203</td>\n",
       "      <td>15943.240860</td>\n",
       "      <td>0.297829</td>\n",
       "      <td>0.696907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>exponential</td>\n",
       "      <td>0.2</td>\n",
       "      <td>150</td>\n",
       "      <td>299.070140</td>\n",
       "      <td>15910.093825</td>\n",
       "      <td>0.397974</td>\n",
       "      <td>0.696907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>square</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>312.444100</td>\n",
       "      <td>15600.427889</td>\n",
       "      <td>0.326773</td>\n",
       "      <td>0.696907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150</td>\n",
       "      <td>301.394527</td>\n",
       "      <td>15915.357341</td>\n",
       "      <td>0.336903</td>\n",
       "      <td>0.698969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>square</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150</td>\n",
       "      <td>321.207746</td>\n",
       "      <td>15622.429930</td>\n",
       "      <td>0.302750</td>\n",
       "      <td>0.698969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>exponential</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>476.688174</td>\n",
       "      <td>15945.714511</td>\n",
       "      <td>0.301013</td>\n",
       "      <td>0.698969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  learning_rate n_estimators  Train RMSE     Test RMSE  \\\n",
       "0        linear            0.2           50  277.002331  16241.628269   \n",
       "4        linear            0.5          100  291.516007  15845.107007   \n",
       "11       square            0.9           50  310.031233  15579.580213   \n",
       "10       square            0.5           50  297.300346  15595.778555   \n",
       "2        linear            0.9           50  290.551777  16011.126391   \n",
       "8        linear            0.9          150  313.094121  15844.606365   \n",
       "9        square            0.2           50  291.018006  15791.047779   \n",
       "18  exponential            0.2           50  276.288132  16087.273380   \n",
       "15       square            0.2          150  308.350599  15714.439825   \n",
       "22  exponential            0.5          100  313.539755  16008.140817   \n",
       "20  exponential            0.9           50  327.840565  15958.289857   \n",
       "17       square            0.9          150  367.815420  15534.447533   \n",
       "14       square            0.9          100  315.195045  15584.591920   \n",
       "26  exponential            0.9          150  538.435011  16000.225061   \n",
       "12       square            0.2          100  319.080274  15723.891137   \n",
       "5        linear            0.9          100  306.810114  15843.304183   \n",
       "25  exponential            0.5          150  403.736089  15930.117280   \n",
       "6        linear            0.2          150  272.211613  16218.307735   \n",
       "3        linear            0.2          100  272.368052  16001.072291   \n",
       "19  exponential            0.5           50  304.704885  15937.346085   \n",
       "21  exponential            0.2          100  297.221861  15924.448774   \n",
       "1        linear            0.5           50  309.321203  15943.240860   \n",
       "24  exponential            0.2          150  299.070140  15910.093825   \n",
       "13       square            0.5          100  312.444100  15600.427889   \n",
       "7        linear            0.5          150  301.394527  15915.357341   \n",
       "16       square            0.5          150  321.207746  15622.429930   \n",
       "23  exponential            0.9          100  476.688174  15945.714511   \n",
       "\n",
       "    Train Accuracy  Test Accuracy  \n",
       "0         0.318090       0.684536  \n",
       "4         0.294356       0.684536  \n",
       "11        0.427786       0.684536  \n",
       "10        0.374240       0.686598  \n",
       "2         0.389291       0.688660  \n",
       "8         0.375109       0.688660  \n",
       "9         0.304776       0.688660  \n",
       "18        0.327062       0.690722  \n",
       "15        0.360926       0.690722  \n",
       "22        0.382923       0.692784  \n",
       "20        0.308828       0.692784  \n",
       "17        0.298698       0.692784  \n",
       "14        0.336903       0.692784  \n",
       "26        0.307959       0.692784  \n",
       "12        0.278726       0.692784  \n",
       "5         0.413893       0.692784  \n",
       "25        0.309696       0.692784  \n",
       "6         0.317221       0.694845  \n",
       "3         0.319537       0.694845  \n",
       "19        0.363531       0.696907  \n",
       "21        0.288567       0.696907  \n",
       "1         0.297829       0.696907  \n",
       "24        0.397974       0.696907  \n",
       "13        0.326773       0.696907  \n",
       "7         0.336903       0.698969  \n",
       "16        0.302750       0.698969  \n",
       "23        0.301013       0.698969  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pd.DataFrame(columns = ['loss', 'learning_rate', 'n_estimators', \"Train RMSE\", \"Test RMSE\", \"Train Accuracy\", \"Test Accuracy\"])\n",
    "\n",
    "for loss in ['linear', 'square', 'exponential']:\n",
    "    for n_estimators in [50,100,150]:\n",
    "        for learning_rate in [0.2, 0.5, 0.9]:\n",
    "            model = AdaBoostRegressor(loss=loss, n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "            model.fit(train[feat], train['target'])\n",
    "            train_pred = model.predict(train[feat])\n",
    "            pred = model.predict(test[feat])\n",
    "            train_rmse, train_acc, test_rmse, test_acc = eval_report(y_train = train['target'], \n",
    "                                                                     pred_train = train_pred, \n",
    "                                                                     y_test = test['target'],\n",
    "                                                                     pred_test = pred,\n",
    "                                                                    is_print = False)\n",
    "            result = result.append({'loss': loss, 'learning_rate':learning_rate, 'n_estimators':n_estimators, \"Train RMSE\":train_rmse, \"Test RMSE\":test_rmse, \"Train Accuracy\":train_acc, \"Test Accuracy\":test_acc}, ignore_index = True)\n",
    "\n",
    "display(result.sort_values('Test Accuracy'))\n",
    "result.sort_values('Test Accuracy').to_csv(path+'result-ada.csv', index = False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>criterion</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>150</td>\n",
       "      <td>mae</td>\n",
       "      <td>50</td>\n",
       "      <td>91.829922</td>\n",
       "      <td>15717.490399</td>\n",
       "      <td>0.984370</td>\n",
       "      <td>0.688660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>mse</td>\n",
       "      <td>50</td>\n",
       "      <td>92.089832</td>\n",
       "      <td>15668.668184</td>\n",
       "      <td>0.985239</td>\n",
       "      <td>0.690722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>mae</td>\n",
       "      <td>50</td>\n",
       "      <td>92.244219</td>\n",
       "      <td>15650.851061</td>\n",
       "      <td>0.984370</td>\n",
       "      <td>0.690722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>mse</td>\n",
       "      <td>100</td>\n",
       "      <td>90.514323</td>\n",
       "      <td>15712.349922</td>\n",
       "      <td>0.985528</td>\n",
       "      <td>0.690722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>mae</td>\n",
       "      <td>100</td>\n",
       "      <td>89.615872</td>\n",
       "      <td>15663.444532</td>\n",
       "      <td>0.984370</td>\n",
       "      <td>0.690722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>mae</td>\n",
       "      <td>50</td>\n",
       "      <td>88.725115</td>\n",
       "      <td>15632.733846</td>\n",
       "      <td>0.986397</td>\n",
       "      <td>0.690722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>150</td>\n",
       "      <td>mse</td>\n",
       "      <td>150</td>\n",
       "      <td>89.816676</td>\n",
       "      <td>15720.995503</td>\n",
       "      <td>0.984949</td>\n",
       "      <td>0.690722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>150</td>\n",
       "      <td>mae</td>\n",
       "      <td>100</td>\n",
       "      <td>88.838169</td>\n",
       "      <td>15712.939684</td>\n",
       "      <td>0.984949</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150</td>\n",
       "      <td>mse</td>\n",
       "      <td>100</td>\n",
       "      <td>92.855080</td>\n",
       "      <td>15607.556793</td>\n",
       "      <td>0.984660</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150</td>\n",
       "      <td>mse</td>\n",
       "      <td>50</td>\n",
       "      <td>91.422335</td>\n",
       "      <td>15647.134086</td>\n",
       "      <td>0.985239</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>mse</td>\n",
       "      <td>100</td>\n",
       "      <td>89.639117</td>\n",
       "      <td>15704.231125</td>\n",
       "      <td>0.986107</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>mse</td>\n",
       "      <td>50</td>\n",
       "      <td>90.602694</td>\n",
       "      <td>15739.607963</td>\n",
       "      <td>0.984660</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>mae</td>\n",
       "      <td>150</td>\n",
       "      <td>88.900385</td>\n",
       "      <td>15684.417031</td>\n",
       "      <td>0.984081</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>mse</td>\n",
       "      <td>150</td>\n",
       "      <td>87.872771</td>\n",
       "      <td>15692.299911</td>\n",
       "      <td>0.985239</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>mse</td>\n",
       "      <td>150</td>\n",
       "      <td>86.496558</td>\n",
       "      <td>15675.721569</td>\n",
       "      <td>0.984949</td>\n",
       "      <td>0.692784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>mae</td>\n",
       "      <td>150</td>\n",
       "      <td>88.897964</td>\n",
       "      <td>15709.358244</td>\n",
       "      <td>0.985528</td>\n",
       "      <td>0.694845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>150</td>\n",
       "      <td>mae</td>\n",
       "      <td>150</td>\n",
       "      <td>88.402887</td>\n",
       "      <td>15728.811783</td>\n",
       "      <td>0.985528</td>\n",
       "      <td>0.694845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>mae</td>\n",
       "      <td>100</td>\n",
       "      <td>91.002759</td>\n",
       "      <td>15636.854480</td>\n",
       "      <td>0.984949</td>\n",
       "      <td>0.698969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth criterion n_estimators  Train RMSE     Test RMSE  Train Accuracy  \\\n",
       "13       150       mae           50   91.829922  15717.490399        0.984370   \n",
       "0         50       mse           50   92.089832  15668.668184        0.985239   \n",
       "1         50       mae           50   92.244219  15650.851061        0.984370   \n",
       "2         50       mse          100   90.514323  15712.349922        0.985528   \n",
       "3         50       mae          100   89.615872  15663.444532        0.984370   \n",
       "7        100       mae           50   88.725115  15632.733846        0.986397   \n",
       "16       150       mse          150   89.816676  15720.995503        0.984949   \n",
       "15       150       mae          100   88.838169  15712.939684        0.984949   \n",
       "14       150       mse          100   92.855080  15607.556793        0.984660   \n",
       "12       150       mse           50   91.422335  15647.134086        0.985239   \n",
       "8        100       mse          100   89.639117  15704.231125        0.986107   \n",
       "6        100       mse           50   90.602694  15739.607963        0.984660   \n",
       "5         50       mae          150   88.900385  15684.417031        0.984081   \n",
       "4         50       mse          150   87.872771  15692.299911        0.985239   \n",
       "10       100       mse          150   86.496558  15675.721569        0.984949   \n",
       "11       100       mae          150   88.897964  15709.358244        0.985528   \n",
       "17       150       mae          150   88.402887  15728.811783        0.985528   \n",
       "9        100       mae          100   91.002759  15636.854480        0.984949   \n",
       "\n",
       "    Test Accuracy  \n",
       "13       0.688660  \n",
       "0        0.690722  \n",
       "1        0.690722  \n",
       "2        0.690722  \n",
       "3        0.690722  \n",
       "7        0.690722  \n",
       "16       0.690722  \n",
       "15       0.692784  \n",
       "14       0.692784  \n",
       "12       0.692784  \n",
       "8        0.692784  \n",
       "6        0.692784  \n",
       "5        0.692784  \n",
       "4        0.692784  \n",
       "10       0.692784  \n",
       "11       0.694845  \n",
       "17       0.694845  \n",
       "9        0.698969  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pd.DataFrame(columns = ['max_depth', 'criterion', 'n_estimators', \"Train RMSE\", \"Test RMSE\", \"Train Accuracy\", \"Test Accuracy\"])\n",
    "\n",
    "for max_depth in [50, 100, 150]:\n",
    "    for n_estimators in [50,100,150]:\n",
    "        for criterion in ['mse', 'mae']:\n",
    "            model = RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators, criterion=criterion)\n",
    "            model.fit(train[feat], train['target'])\n",
    "            train_pred = model.predict(train[feat])\n",
    "            pred = model.predict(test[feat])\n",
    "            train_rmse, train_acc, test_rmse, test_acc = eval_report(y_train = train['target'], \n",
    "                                                                     pred_train = train_pred, \n",
    "                                                                     y_test = test['target'],\n",
    "                                                                     pred_test = pred,\n",
    "                                                                    is_print = False)\n",
    "            result = result.append({'max_depth': max_depth, 'criterion':criterion, 'n_estimators':n_estimators, \"Train RMSE\":train_rmse, \"Test RMSE\":test_rmse, \"Train Accuracy\":train_acc, \"Test Accuracy\":test_acc}, ignore_index = True)\n",
    "\n",
    "display(result.sort_values('Test Accuracy'))\n",
    "result.sort_values('Test Accuracy').to_csv(path+'result-random.csv', index = False)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.62      0.51       215\n",
      "         1.0       0.53      0.34      0.41       270\n",
      "\n",
      "    accuracy                           0.46       485\n",
      "   macro avg       0.48      0.48      0.46       485\n",
      "weighted avg       0.48      0.46      0.45       485\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(train[feat], train['label'])\n",
    "pred = clf.predict(test[feat])\n",
    "make_report(pred, test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.68      0.54       215\n",
      "         1.0       0.58      0.35      0.43       270\n",
      "\n",
      "    accuracy                           0.49       485\n",
      "   macro avg       0.52      0.51      0.49       485\n",
      "weighted avg       0.52      0.49      0.48       485\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = CatBoostClassifier(verbose=0)\n",
    "clf.fit(train[feat], train['label'])\n",
    "pred = clf.predict(test[feat])\n",
    "make_report(pred, test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.67      0.54       215\n",
      "         1.0       0.58      0.36      0.44       270\n",
      "\n",
      "    accuracy                           0.50       485\n",
      "   macro avg       0.52      0.52      0.49       485\n",
      "weighted avg       0.53      0.50      0.49       485\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = XGBClassifier(verbose=0)\n",
    "clf.fit(train[feat], train['label'])\n",
    "pred = clf.predict(test[feat])\n",
    "make_report(pred, test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Results :\n",
      "\n",
      "RMSE : 31.322374853637452\n",
      "Accuracy with 5% : 0.8057887120115774\n",
      "\n",
      "Test Results :\n",
      "\n",
      "RMSE : 15692.485235521754\n",
      "Accuracy with 5% : 0.6927835051546392\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(train[feat], train['target'])\n",
    "train_pred = model.predict(train[feat])\n",
    "pred = model.predict(test[feat])\n",
    "train_rmse, train_acc, test_rmse, test_acc = eval_report(y_train = train['target'], \n",
    "                                                         pred_train = train_pred, \n",
    "                                                         y_test = test['target'],\n",
    "                                                         pred_test = pred,\n",
    "                                                        is_print = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
